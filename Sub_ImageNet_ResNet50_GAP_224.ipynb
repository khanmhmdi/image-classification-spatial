{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sub-ImageNet-ResNet50-GAP-224.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr7495/image-classification-spatial/blob/main/Sub_ImageNet_ResNet50_GAP_224.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJOLaJwx7Tg"
      },
      "source": [
        "#This code shows the implementation of classic feature compression and classification technique\n",
        "# using GLobal Average Pooling layer on ResNet50 and Sub-ImageNet dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1SzEKNRzFL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e116e023-682b-487d-b1e2-71fbdb0a1305"
      },
      "source": [
        "!nvidia-smi #show GPU type"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 18 11:05:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mw_i4iuzHlC"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP8qFi9uWzAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f58bd9c-14ad-48c6-dce0-e3f3102814b2"
      },
      "source": [
        "#download Sub-ImageNet dataset from Kaggle (https://www.kaggle.com/mohammadrahimzadeh/imagenet-70classes)\n",
        "#Get a new download like from kaggle website at the mentioned URL, then replace the link with the \"kaggle_linke\" input in the next line of code \n",
        "\n",
        "!wget -cO - kaggle_link > imagenet_70classes.zip #replace kaggle_link with a new download link from https://www.kaggle.com/mohammadrahimzadeh/imagenet-70classes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 04:07:43--  https://storage.googleapis.com/kaggle-data-sets/941422/1595734/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210422%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210422T040732Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=41a809988838ab3e7d5e1be0de968e66b4adeb247df4a80ae4db4aaf34b1750a0d427e19f050c2f37cd2b8484091c490b5383e1fcc766f312e3d2692f63f73a12593d0acd601c0a0675d1a405ab227ef23ad76d30869502d7c3e5ee8ac396c2ec9177c1906669e44648b424b79f84bd1ba8ec68527a52af2e11954a31049b5752b60ec635716cab575ed85616139579c9a68bc098256539b48231d3a66e6f6775a8e013384516c029d0e4332bc7dbc4ea41709f3c66628fe8076c72a09bf760d93d26faddf07c3d0bea0739cc8f249e0b09b3f67206324e7fcb93cd65e3054fd20effc3c2e46c99cea94eaa438ddbe6571d296c99ffa52404f29dc2b8e190154\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.112, 172.217.164.144, 142.250.73.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2753347742 (2.6G) [application/zip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   2.56G  45.2MB/s    in 36s     \n",
            "\n",
            "2021-04-22 04:08:19 (72.8 MB/s) - written to stdout [2753347742/2753347742]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWNFXlWBWzDg"
      },
      "source": [
        "archive = zipfile.ZipFile('imagenet_70classes.zip') #Extract Sub-ImageNet Dataset\n",
        "for file in archive.namelist():\n",
        "     archive.extract(file, 'data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79KB2ItAzHqb"
      },
      "source": [
        "#Set data augmentation techniques\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,vertical_flip=True\n",
        "                                                             ,zoom_range=0.2,rotation_range=360\n",
        "                                                             ,width_shift_range=0.1,height_shift_range=0.1\n",
        "                                                             ,channel_shift_range=50\n",
        "                                                             ,brightness_range=(0,1.2)\n",
        "                                                             ,preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n",
        "\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8125qva0PJ"
      },
      "source": [
        "#Replace '\\\\' with '/' in CSV files\n",
        "for i in range(len(train_df['filename'])):\n",
        "  name=train_df['filename'][i]\n",
        "  index=name.index('\\\\')\n",
        "  new_name=name[:index]+'/'+name[index+1:]\n",
        "  train_df['filename'][i]=new_name\n",
        "\n",
        "for i in range(len(test_df['filename'])):\n",
        "  name=test_df['filename'][i]\n",
        "  index=name.index('\\\\')\n",
        "  new_name=name[:index]+'/'+name[index+1:]\n",
        "  test_df['filename'][i]=new_name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3dqLamH0TBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50fde4d-4223-4f29-cca6-364d992b3ae7"
      },
      "source": [
        "#Create Data augmentation techniques\n",
        "\n",
        "batch_size=70\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "      dataframe=train_df,\n",
        "      directory='data',\n",
        "      x_col=\"filename\",\n",
        "      y_col=\"class\",\n",
        "      target_size=(224, 224),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',shuffle=True)\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        directory='data',\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31500 validated image filenames belonging to 70 classes.\n",
            "Found 3500 validated image filenames belonging to 70 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo9nEsSx7OfK"
      },
      "source": [
        "name=\"Sub-ImageNet-ResNet50-GAP-224\"\n",
        "!mkdir \"models\" #create new folder for saving checkpoints\n",
        "!mkdir \"reports\" #create new folder for saving evaluation reports\n",
        "keras.backend.clear_session() #clear backend\n",
        "shape=(224,224,3) \n",
        "input_tensor=keras.Input(shape=shape)\n",
        "base_model=keras.applications.ResNet50(input_tensor=input_tensor,weights=None,include_top=False)\n",
        "avg=keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "preds=keras.layers.Dense(70,activation='softmax',\n",
        "                          kernel_initializer=keras.initializers.RandomNormal(mean=0.0,stddev=0.01),\n",
        "                          bias_initializer=keras.initializers.Zeros(),)(avg)\n",
        "model=keras.Model(inputs=base_model.input, outputs=preds)  \n",
        "\n",
        "##################################\n",
        "for layer in model.layers:\n",
        "  layer.trainable = True\n",
        "model.summary()\n",
        "filepath=\"models/%s-{epoch:02d}-{val_accuracy:.4f}.hdf5\"%name\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=False, mode='max') #creating checkpoint to save the best validation accuracy\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#Determine adaptive learning rate with an initialization value of 0.045 and decay of 0.94 every two epochs. 31500 is the number of training images\n",
        "lr_schedule =keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.045,\n",
        "    decay_steps=2*int(31500/batch_size),\n",
        "    decay_rate=0.94,\n",
        "    staircase=True)\n",
        "optimizer=keras.optimizers.SGD(momentum=0.9,learning_rate=lr_schedule)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "hist=model.fit_generator(train_generator, epochs=148,validation_data=validation_generator,shuffle=True,callbacks=callbacks_list) #start training\n",
        "with open('reports/{}.csv'.format(name), mode='w',newline='') as csv_file: #write reports\n",
        "  csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for key in hist.history:\n",
        "    data=[key]\n",
        "    data.extend(hist.history[key])\n",
        "    csv_writer.writerow(data)\n",
        "print(\"Training finished. Reports saved!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

